{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/JFMS_2025/blob/main/Surface_Crack_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNk9xoejq0Gu"
      },
      "source": [
        "# **Make your first experience with TensorFlow-Keras**\n",
        "Our goal is to construct and train a convolutional neural network (CNN) on thousands of concrete surface images in order to detect the presence of cracks. The dataset used is the Surface Crack Detection dataset, which contains images categorized into two classes: 'Positive' (crack present) and 'Negative' (no crack). This hands-on example will help us understand how deep learning models can be applied to real-world civil engineering problems like structural inspection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEFL5miLsJAO"
      },
      "source": [
        "# **Importing necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wbe9-7F0llo4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential # Model type to be used\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout# Make Fully connected (FC) layers\n",
        "from tensorflow.keras.utils import to_categorical # NumPy related tools\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n",
        "from glob import glob\n",
        "import matplotlib.image as mpimg\n",
        "from skimage.transform import resize\n",
        "import pandas as pd\n",
        "from matplotlib.image import imread\n",
        "from skimage.io import imread_collection\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from sklearn import decomposition, preprocessing, svm\n",
        "import sklearn.metrics as metrics #confusion_matrix, accuracy_score\n",
        "from time import sleep\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "! pip install livelossplot\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "sns.set()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUaYe-8hrq0a"
      },
      "source": [
        "## Loading Training and Validation Data\n",
        "\n",
        "The Surface Crack Detection dataset is not included in Keras by default. Therefore, we load it manually from a directory structure where images are stored in subfolders named 'Positive' and 'Negative'. We will read, preprocess, and label the images accordingly to prepare them for training and validation using TensorFlow/Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI5922oZ3Z7K"
      },
      "outputs": [],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"arunrk7/surface-crack-detection\")\n",
        "\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "destination_dir = \"/content/data\"\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# Copy the downloaded files to the new directory\n",
        "for filename in os.listdir(path):\n",
        "    source_path = os.path.join(path, filename)\n",
        "    destination_path = os.path.join(destination_dir, filename)\n",
        "    if os.path.isfile(source_path):\n",
        "        shutil.copy2(source_path, destination_path)  # copy2 preserves metadata\n",
        "    elif os.path.isdir(source_path):\n",
        "      shutil.copytree(source_path, destination_path)\n",
        "\n",
        "print(\"Files copied to:\", destination_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji9IVBzC4BgP"
      },
      "outputs": [],
      "source": [
        "negative = glob('/content/data/Negative/*')\n",
        "positive = glob('/content/data/Positive/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbQM-QQ24jr7"
      },
      "outputs": [],
      "source": [
        "# Limit to 1000 images per class\n",
        "negative_files = negative[:2000]\n",
        "positive_files = positive[:2000]\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for img_path in negative_files:\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.resize(img, (128, 128))\n",
        "  #img = rgb2gray(img) #convert to grayscale\n",
        "  images.append(img)\n",
        "  labels.append(0)\n",
        "\n",
        "for img_path in positive_files:\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.resize(img, (128, 128))\n",
        "  #img = rgb2gray(img) #convert to grayscale\n",
        "  images.append(img)\n",
        "  labels.append(1)\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    images, labels, test_size=0.3, random_state=42\n",
        ")\n",
        "# Split data into train and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.2, random_state=42\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j94bah8itXXQ"
      },
      "source": [
        "Visualization of some input images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2msmk9kllo8"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    num = random.randint(0, len(X_train))\n",
        "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[num]))\n",
        "    plt.axis('off') # Remove the axis and gridlines\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_zCqwWUtsQk"
      },
      "source": [
        "## Formatting the Input Data Layer\n",
        "\n",
        "All images are resized to 128×128 pixels and converted to grayscale. Since we are using a Multi-Layer Perceptron (MLP), each image is flattened into a one-dimensional vector of length 16,384 (128 × 128) before being fed into the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZcXG7IlllpF"
      },
      "outputs": [],
      "source": [
        "# Get the correct number of features based on image dimensions\n",
        "num_features = X_train.shape[1] * X_train.shape[2]* X_train.shape[3]\n",
        "\n",
        "# Reshape X_train and X_val using the calculated num_features\n",
        "X_train = X_train.reshape(X_train.shape[0], num_features).astype('float32')\n",
        "X_val = X_val.reshape(X_val.shape[0], num_features).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train /= 255.\n",
        "X_val /= 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMqOlzCvum99"
      },
      "source": [
        "We then modify our classes (unique digits) to be in the one-hot format, i.e."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noBosoMQupvp"
      },
      "outputs": [],
      "source": [
        "# one hot encode outputs\n",
        "Y_train = to_categorical(y_train)\n",
        "Y_val = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppNdrarWvSEV"
      },
      "source": [
        "# Building the simplest fully connected network (FCN) with just one layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytj_eL4zvFDB"
      },
      "outputs": [],
      "source": [
        "# The Sequential model is a linear stack of layers and is very common.\n",
        "model = Sequential([\n",
        "    Dense(2,input_shape=(num_features,)), # It is the output layer and should be equal to the number of desired classes (10 in this case).\n",
        "    Activation('softmax'),\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyJ_BhHrv52F"
      },
      "source": [
        "## Compiling the Model\n",
        "\n",
        "When compiling a model in Keras, we define the loss function and the optimizer used during training. For our binary classification task (cracked vs. non-cracked surfaces), we use the binary cross-entropy loss function, which is well-suited for comparing predicted probabilities to binary class labels.\n",
        "\n",
        "The optimizer we use is Adam, a widely used method that adjusts the learning rate during training. The model’s output is a probability indicating whether an image is cracked or not, and binary cross-entropy helps measure how close this prediction is to the actual label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_gOe1jFv4dk"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9UNb8kfyp9O"
      },
      "source": [
        "## Train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBlmYIToyfwf"
      },
      "outputs": [],
      "source": [
        "plotlosses = PlotLossesKeras()\n",
        "model.fit(X_train, Y_train,\n",
        "          validation_data=(X_val, Y_val),\n",
        "          epochs=20, batch_size=32,\n",
        "          verbose=1,\n",
        "          callbacks=[plotlosses])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX5YLXkA1e66"
      },
      "source": [
        "## Evaluate Model's Accuracy on Test Data\n",
        "Your test data **Must** be different from the validation data, but in this example, we will use the validation data as the test data as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIaorIub1jw3"
      },
      "outputs": [],
      "source": [
        "Y_test = to_categorical(y_test)\n",
        "X_test = X_test.reshape(X_test.shape[0], num_features).astype('float32')\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8zG9fGI35DI"
      },
      "source": [
        "### Inspecting the output\n",
        "\n",
        "It's always a good idea to inspect the output and make sure everything looks sane. Here we'll look at some examples it gets right, and some examples it gets wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojQlAkh_36R0"
      },
      "outputs": [],
      "source": [
        "# The predict function outputs the probabilities for each class\n",
        "# np.argmax finds the index of the class with the highest probability\n",
        "predicted_classes = np.argmax(model.predict(X_val), axis=-1)\n",
        "\n",
        "# Check which items we got right / wrong\n",
        "correct_indices = np.nonzero(predicted_classes == y_val)[0]\n",
        "\n",
        "incorrect_indices = np.nonzero(predicted_classes != y_val)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4coF9cdC4FuT"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "for i, correct in enumerate(correct_indices[:6]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    image_shape = (int(np.sqrt(X_val[correct].shape[0])), int(np.sqrt(X_val[correct].shape[0])))\n",
        "    plt.imshow(X_val[correct].reshape(image_shape), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_val[correct]))\n",
        "    plt.axis('off') # Remove the axis and gridlines\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAm5wIBo7C1n"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_indices[:6]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_val[incorrect].reshape(128,128), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_val[incorrect]))\n",
        "    plt.axis('off') # Remove the axis and gridlines\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'predicted_classes' and 'y_val' are defined as in your provided code.\n",
        "cm = confusion_matrix(y_val, predicted_classes)\n",
        "\n",
        "# Plot the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "00Tg5ZV8txnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzB25C3M7NBh"
      },
      "source": [
        "# **Let's go Deeper**\n",
        "We will add four more layers to our model. We use Droupout in our model to reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6z6Pj5z7mIv"
      },
      "outputs": [],
      "source": [
        "# Dropout helps protect the model from memorizing or \"overfitting\" the training data.\n",
        "Pkeep=0.25\n",
        "modelDeepFC = Sequential([\n",
        "    Dense(200, input_shape=(num_features,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(100, input_shape=(200,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(60, input_shape=(100,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(30, input_shape=(60,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(2),\n",
        "    Activation('softmax'),\n",
        "])\n",
        "modelDeepFC.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSaOEmsg-pJE"
      },
      "outputs": [],
      "source": [
        "plotlossesdeeper = PlotLossesKeras()\n",
        "\n",
        "lr = 1e-5\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "modelCNN.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "modelDeepFC.fit(X_train, Y_train,\n",
        "          validation_data=(X_val, Y_val),\n",
        "          epochs=20, batch_size=32,\n",
        "          verbose=1,\n",
        "          callbacks=[plotlossesdeeper])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_gM34gjBsAW"
      },
      "source": [
        "# **Let's go furter with introducing CNN**\n",
        "Before, we built a network that accepts the normalized pixel values of each value and operates soley on those values. What if we could instead feed different features (e.g. curvature, edges) of each image into a network, and have the network learn which features are important for classifying an image?\n",
        "\n",
        "This possible through convolution! Convolution applies kernels (filters) that traverse through each image and generate feature maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3_HL1Z5CsMF"
      },
      "outputs": [],
      "source": [
        "# Again, do some formatting\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    images, labels, test_size=0.3, random_state=42\n",
        ")\n",
        "# Split data into train and test sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Except we do not flatten each image into a 1D vector because we want to perform convolutions first\n",
        "img_height = X_train.shape[1]\n",
        "img_width = X_train.shape[2]\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_height, img_width, 3).astype('float32') #add an additional dimension to represent the single-channel\n",
        "X_val = X_val.reshape(X_val.shape[0], img_height, img_width, 3).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], img_height, img_width, 3).astype('float32')\n",
        "\n",
        "X_train /= 255.                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_val /= 255.\n",
        "X_test /= 255.\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Validation matrix shape\", X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VuttSwGDQdB"
      },
      "outputs": [],
      "source": [
        "# one hot encode outputs\n",
        "Y_train = to_categorical(y_train)\n",
        "Y_val = to_categorical(y_val)\n",
        "Y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsVz160NDdwF"
      },
      "outputs": [],
      "source": [
        "modelCNN = Sequential([\n",
        "\n",
        "    # Convolution Layer 1\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)), # 32 different 3x3 kernels -- so 32 feature maps\n",
        "    MaxPooling2D(pool_size=(2, 2)), # Pool the max values over a 2x2 kernel\n",
        "\n",
        "    # Convolution Layer 2\n",
        "    Conv2D(64, (3, 3), activation='relu'), # 64 different 3x3 kernels\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolution Layer 3\n",
        "    Conv2D(128, (3, 3), activation='relu'), # 128 different 3x3 kernels\n",
        "\n",
        "    Flatten(), # Flatten final 28x28x128 output matrix into a 1024-length vector\n",
        "\n",
        "    # Fully Connected Layer 4\n",
        "    Dense(256,activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(2),\n",
        "    Activation('softmax'),\n",
        "])\n",
        "modelCNN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)"
      ],
      "metadata": {
        "id": "_XRp0R2NaIBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2kzBiLRE3Hw"
      },
      "outputs": [],
      "source": [
        "plotlossesCNN = PlotLossesKeras()\n",
        "\n",
        "lr = 1e-5\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "modelCNN.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "modelCNN.fit(X_train, Y_train,\n",
        "          validation_data=(X_val, Y_val),\n",
        "          epochs=200, batch_size=32,\n",
        "          verbose=1,\n",
        "          callbacks=[plotlossesCNN, early_stopping, model_checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipCAB6BZMZjh"
      },
      "source": [
        "**Evaluation and Prediction**\n",
        "\n",
        "We can use our model to make a prediction on new images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNFXqmiSOMtp"
      },
      "outputs": [],
      "source": [
        "modelCNN.evaluate(X_test,Y_test) #Evaluation of the model on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The predict function outputs the probabilities for each class\n",
        "# np.argmax finds the index of the class with the highest probability\n",
        "predicted_classes = np.argmax(modelCNN.predict(X_test), axis=-1) # Changed model to modelCNN\n",
        "\n",
        "# Check which items we got right / wrong\n",
        "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
        "\n",
        "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]"
      ],
      "metadata": {
        "id": "eOFyNMz0Hxz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_indices[:6]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    # Reshape to the original image size (128x128)\n",
        "    plt.imshow(X_test[incorrect].reshape(224,224), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n",
        "    plt.axis('off') # Remove the axis and gridlines\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "NyalVZ2hHtdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'predicted_classes' and 'y_val' are defined as in your provided code.\n",
        "cm = confusion_matrix(y_test, predicted_classes)\n",
        "\n",
        "# Plot the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qugm5AmYHLdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tuIgdGAEY3Iz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}